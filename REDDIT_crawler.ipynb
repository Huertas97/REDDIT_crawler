{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env_reddit_credentials\")  # Carga las variables de entorno desde el archivo .env\n",
    "\n",
    "client_id = os.getenv('client_id')\n",
    "client_secret = os.getenv('client_secret')\n",
    "user_agent = os.getenv('user_agent')\n",
    "username = os.getenv('username')\n",
    "password = os.getenv('password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent,\n",
    "    username=username,\n",
    "    password=password\n",
    "    )\n",
    "\n",
    "# Enable read-only mode\n",
    "# reddit.read_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit(\"python\")\n",
    "\n",
    "top_post = subreddit.top(limit=2)\n",
    "\n",
    "new_posts = subreddit.new(limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title -  Lad wrote a Python script to download Alexa voice recordings, he didn't expect this email.\n",
      "ID -  g53lxf\n",
      "Link flair text -  Discussion\n",
      "Link flair template ID -  0df42996-1c5e-11ea-b1a0-0e44e1c5b731\n",
      "Comment ID -  fo1gur8\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo17vty\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo12gp8\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1a4vn\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo19rw3\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo18z22\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1fsfc\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1r4mx\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo19xj9\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1gxkk\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1a3gv\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1cpm4\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1jdib\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo21h46\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2rvrw\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1a4l1\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1amhm\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2ap22\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo4bxzs\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo295qq\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1q2qp\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1u76v\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1yq3j\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo25svo\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo3we7d\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  hkiyafj\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1bzyb\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo24sp4\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1hoyj\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1q2hr\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1qv10\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1rwn1\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo1z0h0\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo21lry\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo27zw5\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2hw67\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2nodu\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2un3h\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2w0wv\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2y7hk\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2zj9j\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo33zrw\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo37rrj\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo38j8o\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo3elbx\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo3igkc\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo3nbe8\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo41pxl\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo47zik\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo4mfn7\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fpezi77\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fpgevfz\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fppkti9\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fq1z3k2\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fqyjso5\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  ftc932u\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo2an6r\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo4np1d\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fp2mjy2\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  fo49ktk\n",
      "Comment parent ID -  t3_g53lxf\n",
      "Comment ID -  hiln18d\n",
      "Comment parent ID -  t3_g53lxf\n",
      "---------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit(\"python\")\n",
    "\n",
    "top_post = subreddit.top(limit=1)\n",
    "\n",
    "new_posts = subreddit.new(limit=2)\n",
    "\n",
    "for post in top_post:\n",
    "    print(\"Title - \", post.title)\n",
    "    print(\"ID - \", post.id)\n",
    "    # print(\"Username - \", post.author)\n",
    "    # print(\"URL - \", post.url)\n",
    "    # print(\"Score - \", post.score)\n",
    "    # print(\"Comment count - \", post.num_comments)\n",
    "    # print(\"Created - \", post.created_utc)\n",
    "    # print(\"stickied - \", post.stickied)\n",
    "    # print(\"upvote_ratio - \", post.upvote_ratio)\n",
    "    # print(\"Author flair text - \", post.author_flair_text)\n",
    "    # print(\"Clicked - \", post.clicked)\n",
    "    # print(\"Distinguished - \", post.distinguished)\n",
    "    # print(\"Edited - \", post.edited)\n",
    "    # print(\"Is original content - \", post.is_original_content)\n",
    "    # print(\"Is self - \", post.is_self)\n",
    "    # print(\"Locked - \", post.locked)\n",
    "    # print(\"Name - \", post.name)\n",
    "    # print(\"Over 18 - \", post.over_18)\n",
    "    # print(\"Permalink - \", post.permalink)\n",
    "    # print(\"Saved - \", post.saved)\n",
    "    # print(\"Selftext - \", post.selftext)\n",
    "    # print(\"Spoiler - \", post.spoiler)\n",
    "    # print(\"Stickied - \", post.stickied)\n",
    "    # print(\"Subreddit - \", post.subreddit)\n",
    "    \n",
    "    if post.link_flair_text is not None:\n",
    "        print(\"Link flair text - \", post.link_flair_text)\n",
    "        print(\"Link flair template ID - \", post.link_flair_template_id)  \n",
    "\n",
    "    if post.num_comments > 0:\n",
    "        \n",
    "        # comments = post.comments\n",
    "        # for comment_id in comments:\n",
    "        post_comments = reddit.submission(id=post.id) # id for the post to get comments from\n",
    "        comments = post_comments.comments\n",
    "        for n, comment in enumerate(comments):\n",
    "            # print(\"Comment number - \", n)\n",
    "            # print(\"Comment author - \", str(comment.author))  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "            # print(\"Comment - \", comment.body)\n",
    "            # print(\"Comment body HTML - \", comment.body_html)\n",
    "            # print(\"Comment created - \", comment.created_utc)\n",
    "            # print(\"Comment distinguished - \", comment.distinguished)\n",
    "            # print(\"Comment edited - \", comment.edited)\n",
    "            print(\"Comment ID - \", comment.id)\n",
    "            # print(\"Comment is submitter - \", comment.is_submitter)\n",
    "            # print(\"Comment link ID - \", comment.link_id)\n",
    "            print(\"Comment parent ID - \", comment.parent_id)\n",
    "            # print(\"Comment permalink - \", comment.permalink)\n",
    "            # print(\"Comment replies - \", comment.replies)\n",
    "            # print(\"Comment saved - \", comment.saved)\n",
    "            # print(\"Comment score - \", comment.score)\n",
    "            # print(\"Comment stickied - \", comment.stickied)\n",
    "            # print(\"Comment submission - \", comment.submission)\n",
    "            # print(\"Comment subreddit - \", str(comment.subreddit))  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "            # print(\"Comment subreddit ID - \", comment.subreddit_id)\n",
    "\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1atyfk6\n"
     ]
    }
   ],
   "source": [
    "f = reddit.subreddit(\"programming\").controversial(\n",
    "    time_filter=\"day\"\n",
    ")\n",
    "\n",
    "for f_in in f:\n",
    "    print(f_in)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reddit.com//r/programming/comments/1atyfk6/why_you_should_plan_your_day_as_a_software/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = reddit.submission(id=\"1atyfk6\") # id for the post to get comments from\n",
    "# for post in post_comments.top():\n",
    "#     print(\"Title - \", post.title)\n",
    "#     print(\"ID - \", post.id)\n",
    "\n",
    "\"https://www.reddit.com/\" + submission.permalink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interesting that there‚Äôs no mention of meetings. These are by far the biggest productivity killer. People abuse standup also. The whole team doesn‚Äôt need to hear you babble on about your reasoning for service fabric region redundancy ‚Ä¶ or whatever.\n",
      "\t REPLY -> As a WFH employee, I miss the days when stand-up was regulated by people getting tired of standing up.\n",
      "\n",
      "A line I have found helpful is ‚Äúthis sounds like a great topic for a break out‚Äù - the talker feels validated and the meeting moves on.\n",
      "\t REPLY -> Just the thought of a meeting can usually ruin my entire day as a programmer. There's also the pressure to be always available, always check emails, etc. I don't want AI assistance to write code - I can do that already. I want an AI assistant that will take meetings, field questions, answer emails, and respond to Teams chats for me.\n",
      "\t REPLY -> Honestly, work with your manager to take back your calendar as best you can. I‚Äôm a manager and part of my job is to help fill in for my employees in meetings that aren‚Äôt essential for them to be in. I know what they are working on, the status of those items. I can fill in for them and they can have uninterrupted focus time. \n",
      "\n",
      "If my team *wants* to do that because they want to become a TL or EM, I won‚Äôt take that opportunity away from them, but if they are finding it hard to do what they enjoy and need to do, I fix that.\n",
      "Well, I rarely see it in that way, accepted vs unaccepted‚Ä¶ Lol I despite all interruptions. What I‚Äôm trying to evaluate is if bypassing an interruption would slow down the team too much or not, and if I‚Äôm really needed to solve the problems. As a senior developer, interruptions are normal and expected up to a point. And sometime, helping people goes a long way. So, instead of being an interruption avoider, I try to evaluate the worth of it. But I always, always deny any attempt to add me to ad hoc meetings (like a QA calling me out of the blue) as these things are the worst üòÇ and cannot tell if it‚Äôs worth it upfront.\n",
      "\t REPLY -> Yeah, it's an evaluation. Sometimes the interruption can just be re-scheduled, minimizing the impact on your work or on the person requesting your attention\n",
      "\n",
      "... because 10%+ of the population has ADHD, many of whom are drawn to programming, and having a plan/schedule is incredibly important for us?\n",
      "\t REPLY -> And we hate interruptions (even if they‚Äôre planned ones like meetings). It‚Äôs hard to get into working on a big programming task when I know I‚Äôll have to put it down in 2 hours. Same goes for parenting and personal projects.\n",
      "\t REPLY -> 10%\n",
      "\n",
      "‚Ä¶ (X) Doubt\n",
      "My problem is I usually have 10 things I want / need to get done in one day, not one month¬†üòÇ\n",
      "\n",
      "But actually, that keeps me from doing the one thing that‚Äôs truly important. Making a plan for that one single big thing really helps. If I finish that, I‚Äôll feel good about my day.¬†\n",
      "\n",
      "And I‚Äôll probably get several others done as well - in addition to the 237 slack interruptions.¬†üòÖ\n",
      "\n",
      "We do more by doing less at once.¬†\n",
      "Make a plan for that one thing.\n",
      "Great advice.\n",
      "What jobs should you not plan your day?\n",
      "\t REPLY -> A Nurse. A Police Officer. A Fire Fighter. A Cab Driver. A Waitress. Shit, I can barely think of a job below management-level where planning your day is an option.\n",
      "Seems like we're talking about Agile and Sprints without saying it.. are those bad words now?\n"
     ]
    }
   ],
   "source": [
    "for c in submission.comments:\n",
    "    print(c.body)\n",
    "\n",
    "    for reply in c.replies:\n",
    "        print(f\"\\t REPLY -> {reply.body}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save REDDIT DATA in JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dacad251335413387666df6d2ebe047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Posts:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post with ID g53lxf already exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0aedbc6ebd45a5b9d7b54e33648c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Comments:   0%|          | 0/305 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a14a7f46e3482691ff3c6e39a4fe53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Replies:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323ca3392e624192a618333e1fcc9ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Replies:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "subreddit_name = \"python\"\n",
    "subrredit_path = f\"REDDIT_DATA/{subreddit_name}\"\n",
    "n_posts_retrieved = 2\n",
    "\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "top_post = subreddit.top(limit=n_posts_retrieved)\n",
    "\n",
    "# Crear una carpeta con el nombre del subreddit si no existe\n",
    "if not os.path.exists(subrredit_path):\n",
    "    os.makedirs(subrredit_path)\n",
    "\n",
    "# new_posts = subreddit.new(limit=n_posts_retrieved)\n",
    "\n",
    "\n",
    "\n",
    "data = []\n",
    " \n",
    "for post in tqdm(top_post, desc=\"Posts\", total=n_posts_retrieved):\n",
    "    # check if the post.id file exists\n",
    "    if os.path.exists(f'{subrredit_path}/{post.id}.json'):\n",
    "        print(f\"Post with ID {post.id} already exists\")\n",
    "        continue\n",
    "\n",
    "    post_data = {\n",
    "        \"Title\": post.title,\n",
    "        \"ID\": post.id,\n",
    "        \"Username\": str(post.author),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "        \"URL\": post.url,\n",
    "        \"Score\": post.score,\n",
    "        \"Comment count\": post.num_comments,\n",
    "        \"Created\": post.created_utc,\n",
    "        \"stickied\": post.stickied,\n",
    "        \"upvote_ratio\": post.upvote_ratio,\n",
    "        \"Author flair text\": post.author_flair_text,\n",
    "        \"Clicked\": post.clicked,\n",
    "        \"Distinguished\": post.distinguished,\n",
    "        \"Edited\": post.edited,\n",
    "        \"Is original content\": post.is_original_content,\n",
    "        \"Is self\": post.is_self,\n",
    "        \"Locked\": post.locked,\n",
    "        \"Name\": post.name,\n",
    "        \"Over 18\": post.over_18,\n",
    "        \"Permalink\": post.permalink,\n",
    "        \"Saved\": post.saved,\n",
    "        \"Selftext\": post.selftext,\n",
    "        \"Spoiler\": post.spoiler,\n",
    "        \"Stickied\": post.stickied,\n",
    "        \"Subreddit\": str(post.subreddit),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "        \"Link flair text\": post.link_flair_text if post.link_flair_text is not None else None,\n",
    "        \"Link flair template ID\": post.link_flair_template_id if post.link_flair_text is not None else None,\n",
    "        # \"Comments\": []\n",
    "    }\n",
    "\n",
    "    # Guardar en un archivo JSON con el ID del post como nombre\n",
    "    with open(f'{subrredit_path}/{post.id}.json', 'w') as f:\n",
    "        json.dump(post_data, f)\n",
    "\n",
    "    if post.num_comments > 0:\n",
    "        post_comments = reddit.submission(id=post.id) # id for the post to get comments from\n",
    "        comments = post_comments.comments\n",
    "\n",
    "        # Crear una carpeta para los comentarios si no existe\n",
    "        comments_folder = f'{subrredit_path}/Comments'\n",
    "        if not os.path.exists(comments_folder):\n",
    "            os.makedirs(comments_folder)\n",
    "\n",
    "        for comment in tqdm(comments[:2], desc=\"Comments\", total=len(post.comments), leave=False):\n",
    "            comment_data = {\n",
    "                \"Comment author\": str(comment.author),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                \"Comment\": comment.body,\n",
    "                \"Comment body HTML\": comment.body_html,\n",
    "                \"Comment created\": comment.created_utc,\n",
    "                \"Comment distinguished\": comment.distinguished,\n",
    "                \"Comment edited\": comment.edited,\n",
    "                \"Comment ID\": comment.id,\n",
    "                \"Comment is submitter\": comment.is_submitter,\n",
    "                \"Comment link ID\": comment.link_id,\n",
    "                \"Comment parent ID\": comment.parent_id,\n",
    "                \"Comment permalink\": comment.permalink,\n",
    "                # \"Comment replies\": comment.replies,\n",
    "                \"Comment saved\": comment.saved,\n",
    "                \"Comment score\": comment.score,\n",
    "                \"Comment stickied\": comment.stickied,\n",
    "                # \"Comment submission\": comment.submission,\n",
    "                \"Comment subreddit\": str(comment.subreddit),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                \"Comment subreddit ID\": comment.subreddit_id\n",
    "            }\n",
    "            # post_data[\"Comments\"].append(comment_data)\n",
    "\n",
    "            if comment.replies:\n",
    "                # Crear una carpeta para los replies si no existe\n",
    "                replies_folder = f'{comments_folder}/Replies'\n",
    "                if not os.path.exists(replies_folder):\n",
    "                    os.makedirs(replies_folder)\n",
    "\n",
    "                for reply in tqdm(comment.replies, desc=\"Replies\", leave=False):\n",
    "                    reply_data = {\n",
    "                        \"Reply author\": str(reply.author),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                        \"Reply\": reply.body,\n",
    "                        \"Reply body HTML\": reply.body_html,\n",
    "                        \"Reply created\": reply.created_utc,\n",
    "                        \"Reply distinguished\": reply.distinguished,\n",
    "                        \"Reply edited\": reply.edited,\n",
    "                        \"Reply ID\": reply.id,\n",
    "                        \"Reply is submitter\": reply.is_submitter,\n",
    "                        \"Reply link ID\": reply.link_id,\n",
    "                        \"Reply parent ID\": reply.parent_id,\n",
    "                        \"Reply permalink\": reply.permalink,\n",
    "                        \"Reply saved\": reply.saved,\n",
    "                        \"Reply score\": reply.score,\n",
    "                        \"Reply stickied\": reply.stickied,\n",
    "                        \"Reply subreddit\": str(reply.subreddit),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                        \"Reply subreddit ID\": reply.subreddit_id\n",
    "                    }\n",
    "\n",
    "                    # Guardar cada reply en un archivo JSON con el ID del post y el ID del reply como nombre\n",
    "                    with open(f'{replies_folder}/{post.id}_{reply.id}.json', 'w') as f:\n",
    "                        json.dump(reply_data, f)\n",
    "\n",
    "            # Guardar cada comentario en un archivo JSON con el ID del post y el ID del comentario como nombre\n",
    "            with open(f'{comments_folder}/{post.id}_{comment.id}.json', 'w') as f:\n",
    "                json.dump(comment_data, f)\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fxj8xpn\n",
      "t1_fxj8xpn\n",
      "That's still a request. Yes, it will get rate limited.\n",
      "t1_fxj8xpn\n",
      "`submission = reddit.submission(id='***')` This line looks like a request to me. How else is he going to get the up-to-date stats? Also as the other poster said, submitting is still a request.\n",
      "t1_fxj8xpn\n",
      "You're great at figuring stuff out.\n",
      "t1_fxj8xpn\n",
      "I bet you sweat glitter.\n"
     ]
    }
   ],
   "source": [
    "print(reply.id)\n",
    "for r in reply.replies:\n",
    "    print(r.parent_id)\n",
    "    print(r.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga Recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Posts:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Posts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post with ID g53lxf already exists\n",
      "Post with ID hoolsm already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm  # Aseg√∫rate de tener tqdm instalado para la barra de progreso\n",
    "\n",
    "subreddit_name = \"python\"\n",
    "subreddit_path = f\"REDDIT_DATA/{subreddit_name}\"\n",
    "n_posts_retrieved = 2\n",
    "\n",
    "# Asumiendo que 'reddit' ya est√° definido y autenticado\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "top_post = subreddit.top(limit=n_posts_retrieved)\n",
    "\n",
    "# Crear una carpeta con el nombre del subreddit si no existe\n",
    "if not os.path.exists(subreddit_path):\n",
    "    os.makedirs(subreddit_path)\n",
    "\n",
    "def process_comments(comments, parent_id, path_prefix):\n",
    "    for comment in tqdm(comments[:1], desc=\"Processing comments\", leave=False):\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            continue  # Saltar instancias de MoreComments\n",
    "\n",
    "        comment_data = {\n",
    "                \"Comment author\": str(comment.author),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                \"Comment\": comment.body,\n",
    "                \"Comment body HTML\": comment.body_html,\n",
    "                \"Comment created\": comment.created_utc,\n",
    "                \"Comment distinguished\": comment.distinguished,\n",
    "                \"Comment edited\": comment.edited,\n",
    "                \"Comment ID\": comment.id,\n",
    "                \"Comment is submitter\": comment.is_submitter,\n",
    "                \"Comment link ID\": comment.link_id,\n",
    "                \"Comment parent ID\": comment.parent_id,\n",
    "                \"Comment permalink\": comment.permalink,\n",
    "                # \"Comment replies\": comment.replies,\n",
    "                \"Comment saved\": comment.saved,\n",
    "                \"Comment score\": comment.score,\n",
    "                \"Comment stickied\": comment.stickied,\n",
    "                # \"Comment submission\": comment.submission,\n",
    "                \"Comment subreddit\": str(comment.subreddit),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "                \"Comment subreddit ID\": comment.subreddit_id\n",
    "        }\n",
    "\n",
    "        comment_file_path = os.path.join(path_prefix, f'{parent_id}_{comment.id}.json')\n",
    "        with open(comment_file_path, 'w') as f:\n",
    "            json.dump(comment_data, f)\n",
    "\n",
    "        # Llamada recursiva para manejar respuestas al comentario\n",
    "        if comment.replies:\n",
    "            replies_path = os.path.join(path_prefix, \"Replies\")\n",
    "            if not os.path.exists(replies_path):\n",
    "                os.makedirs(replies_path)\n",
    "\n",
    "            process_comments(comment.replies, comment.id, replies_path)\n",
    "\n",
    "for post in tqdm(top_post, desc=\"Posts\", total=n_posts_retrieved):\n",
    "    # check if the post.id file exists\n",
    "    if os.path.exists(f'{subrredit_path}/{post.id}.json'):\n",
    "        print(f\"Post with ID {post.id} already exists\")\n",
    "        continue\n",
    "\n",
    "    post_data = {\n",
    "        \"Title\": post.title,\n",
    "        \"ID\": post.id,\n",
    "        \"Username\": str(post.author),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "        \"URL\": post.url,\n",
    "        \"Score\": post.score,\n",
    "        \"Comment count\": post.num_comments,\n",
    "        \"Created\": post.created_utc,\n",
    "        \"stickied\": post.stickied,\n",
    "        \"upvote_ratio\": post.upvote_ratio,\n",
    "        \"Author flair text\": post.author_flair_text,\n",
    "        \"Clicked\": post.clicked,\n",
    "        \"Distinguished\": post.distinguished,\n",
    "        \"Edited\": post.edited,\n",
    "        \"Is original content\": post.is_original_content,\n",
    "        \"Is self\": post.is_self,\n",
    "        \"Locked\": post.locked,\n",
    "        \"Name\": post.name,\n",
    "        \"Over 18\": post.over_18,\n",
    "        \"Permalink\": post.permalink,\n",
    "        \"Saved\": post.saved,\n",
    "        \"Selftext\": post.selftext,\n",
    "        \"Spoiler\": post.spoiler,\n",
    "        \"Stickied\": post.stickied,\n",
    "        \"Subreddit\": str(post.subreddit),  # Convertir a cadena para evitar errores de serializaci√≥n\n",
    "        \"Link flair text\": post.link_flair_text if post.link_flair_text is not None else None,\n",
    "        \"Link flair template ID\": post.link_flair_template_id if post.link_flair_text is not None else None,\n",
    "        # \"Comments\": []\n",
    "    }\n",
    "\n",
    "    # Guardar en un archivo JSON con el ID del post como nombre\n",
    "    with open(f'{subrredit_path}/{post.id}.json', 'w') as f:\n",
    "        json.dump(post_data, f)\n",
    "\n",
    "    if post.num_comments > 0:\n",
    "        post_comments = reddit.submission(id=post.id).comments\n",
    "        comments_path = os.path.join(subreddit_path, \"Comments\")\n",
    "\n",
    "        if not os.path.exists(comments_path):\n",
    "            os.makedirs(comments_path)\n",
    "\n",
    "        process_comments(post_comments, post.id, comments_path)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# Trackeo de comentarios y replies en carpetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruir la conversacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Comment author': 'natanb223', 'Comment': '453 now', 'Comment body HTML': '<div class=\"md\"><p>453 now</p>\\n</div>', 'Comment created': 1609790102.0, 'Comment distinguished': None, 'Comment edited': False, 'Comment ID': 'gi3mwss', 'Comment is submitter': False, 'Comment link ID': 't3_hoolsm', 'Comment parent ID': 't3_hoolsm', 'Comment permalink': '/r/Python/comments/hoolsm/this_post_has/gi3mwss/', 'Comment saved': False, 'Comment score': 1, 'Comment stickied': False, 'Comment subreddit': 'Python', 'Comment subreddit ID': 't5_2qh0y'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "subreddit_name = \"python\"\n",
    "data_path = f\"REDDIT_DATA/{subreddit_name}\"\n",
    "start_id = \"gi3mwss\"  # El ID desde el cual quieres reconstruir la conversaci√≥n\n",
    "\n",
    "def read_json_files(directory):\n",
    "    data = {}\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    file_data = json.load(f)\n",
    "                    data[file_data['Comment ID'] if 'Comment ID' in file_data else file_data['ID']] = file_data\n",
    "    return data\n",
    "\n",
    "def reconstruct_conversation(data, start_id):\n",
    "    conversation = []\n",
    "    stack = [start_id]\n",
    "    while stack:\n",
    "        current_id = stack.pop()\n",
    "        if current_id in data:\n",
    "            current_data = data[current_id]\n",
    "            conversation.append(current_data)\n",
    "            if 'Replies' in current_data:\n",
    "                for reply_id in current_data['Replies']:\n",
    "                    stack.append(reply_id)\n",
    "    return conversation\n",
    "\n",
    "# Lee todos los archivos JSON desde el directorio de datos\n",
    "data = read_json_files(data_path)\n",
    "\n",
    "# Reconstruye la conversaci√≥n desde el ID proporcionado\n",
    "conversation = reconstruct_conversation(data, start_id)\n",
    "\n",
    "# Imprime o procesa la conversaci√≥n reconstruida\n",
    "for item in conversation:\n",
    "    print(item)  # O procesa cada elemento de la conversaci√≥n seg√∫n sea necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'This post has:', 'ID': 'hoolsm', 'Username': 'Krukerfluk', 'URL': 'https://www.reddit.com/r/Python/comments/hoolsm/this_post_has/', 'Score': 9234, 'Comment count': 437, 'Created': 1594386373.0, 'stickied': False, 'upvote_ratio': 0.91, 'Author flair text': None, 'Clicked': False, 'Distinguished': None, 'Edited': 1609339473.0, 'Is original content': False, 'Is self': True, 'Locked': False, 'Name': 't3_hoolsm', 'Over 18': False, 'Permalink': '/r/Python/comments/hoolsm/this_post_has/', 'Saved': False, 'Selftext': '9777 upvotes,\\n\\n967 downvotes\\n\\nand 452 comments!', 'Spoiler': False, 'Stickied': False, 'Subreddit': 'Python', 'Link flair text': 'I Made This', 'Link flair template ID': 'd7dfae22-4113-11ea-b9fe-0e741fe75651'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "subreddit_name = \"python\"\n",
    "data_path = f\"REDDIT_DATA/{subreddit_name}\"\n",
    "start_id = \"hoolsm\"  # El ID desde el cual quieres reconstruir la conversaci√≥n\n",
    "\n",
    "def read_json_files(directory):\n",
    "    data = {}\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                with open(os.path.join(root, file), 'r') as f:\n",
    "                    file_data = json.load(f)\n",
    "                    data[file_data['Comment ID'] if 'Comment ID' in file_data else file_data['ID']] = file_data\n",
    "    return data\n",
    "\n",
    "def reconstruct_conversation(data, start_id):\n",
    "    conversation = []\n",
    "    stack = [start_id]\n",
    "    while stack:\n",
    "        current_id = stack.pop()\n",
    "        if current_id in data:\n",
    "            current_data = data[current_id]\n",
    "            conversation.append(current_data)\n",
    "            if 'Replies' in current_data:\n",
    "                for reply_id in current_data['Replies']:\n",
    "                    stack.append(reply_id)\n",
    "    return conversation\n",
    "\n",
    "# Lee todos los archivos JSON desde el directorio de datos\n",
    "data = read_json_files(data_path)\n",
    "\n",
    "# Reconstruye la conversaci√≥n desde el ID proporcionado\n",
    "conversation = reconstruct_conversation(data, start_id)\n",
    "\n",
    "# Imprime o procesa la conversaci√≥n reconstruida\n",
    "for item in conversation:\n",
    "    print(item)  # O procesa cada elemento de la conversaci√≥n seg√∫n sea necesario\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_OSINT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
